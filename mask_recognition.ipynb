{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 92366 images belonging to 2 classes.\n",
      "Found 6882 images belonging to 2 classes.\n",
      "{'face': 0, 'masked_face': 1}\n",
      "{'face': 0, 'masked_face': 1}\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "TRAIN_DATA_PATH = '/home/mist/mask_datasets/train/'\n",
    "VALID_DATA_PATH = '/home/mist/mask_datasets/valid/'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_EPOCHS = 5\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_PATH,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)  # Set as training dataset\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    VALID_DATA_PATH,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)  # Set as validation dataset\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for train images\n",
      "Check for valid images\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for valid images\n",
    "g = os.walk(TRAIN_DATA_PATH)\n",
    "for path,dir_list,file_list in g:  \n",
    "    for file_name in file_list:\n",
    "        try:\n",
    "            plt.imread(path + '/'+ file_name)\n",
    "        except:\n",
    "            print(path + \"/\" + file_name)\n",
    "print(\"Check for train images\")\n",
    "\n",
    "g = os.walk(VALID_DATA_PATH)\n",
    "for path,dir_list,file_list in g:  \n",
    "    for file_name in file_list:\n",
    "        try:\n",
    "            plt.imread(path + '/'+ file_name)\n",
    "        except:\n",
    "            print(path + \"/\" + file_name)\n",
    "\n",
    "print(\"Check for valid images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2886/2886 [==============================] - 1154s 400ms/step - loss: 0.0096 - binary_accuracy: 0.9964 - val_loss: 0.0013 - val_binary_accuracy: 0.9991 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "2886/2886 [==============================] - 1156s 401ms/step - loss: 0.0046 - binary_accuracy: 0.9988 - val_loss: 0.0039 - val_binary_accuracy: 0.9989 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "2886/2886 [==============================] - 1144s 397ms/step - loss: 0.0042 - binary_accuracy: 0.9989 - val_loss: 0.0036 - val_binary_accuracy: 0.9994 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "2886/2886 [==============================] - ETA: 0s - loss: 0.0036 - binary_accuracy: 0.9991\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "2886/2886 [==============================] - 1145s 397ms/step - loss: 0.0036 - binary_accuracy: 0.9991 - val_loss: 0.0016 - val_binary_accuracy: 0.9999 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "2886/2886 [==============================] - 1151s 399ms/step - loss: 0.0021 - binary_accuracy: 0.9995 - val_loss: 0.0023 - val_binary_accuracy: 0.9997 - lr: 5.0000e-05\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: mask_recongnition/assets\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=[IMG_HEIGHT, IMG_WIDTH, 3],\n",
    "                         classes=NUM_CLASSES)\n",
    "\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "dense = keras.layers.Dense(1024, activation = 'relu')(avg)\n",
    "dense = keras.layers.Dense(1024, activation = 'relu')(dense)\n",
    "dense = keras.layers.Dense(512, activation = 'relu')(dense)\n",
    "preds = keras.layers.Dense(NUM_CLASSES, activation = 'sigmoid')(dense)\n",
    "model = keras.Model(inputs = base_model.input, outputs = preds)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    verbose=1)\n",
    "\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True\n",
    "    \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr=1e-4),\n",
    "              metrics = ['binary_accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=TRAIN_EPOCHS,\n",
    "    steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n//validation_generator.batch_size,\n",
    "    callbacks=[reduce_lr])\n",
    "\n",
    "model.save('mask_recongnition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
